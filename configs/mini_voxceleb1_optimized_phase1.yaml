# OPTIMIZED CONFIG - Phase 1 Quick Wins
# Expected improvement: 15-30% MinDCF reduction
# Based on mini_voxceleb1_config.yaml with optimizations

## Data loader - OPTIMIZED
augment: true
batch_size: 32
max_frames: 200
eval_frames: 0
nDataLoaderThread: 4
max_seg_per_spk: 500
seed: 42

## Training details
test_interval: 1
trainfunc: aamsoftmax
patience: 15
max_epoch: 100

## Optimizer - IMPROVED (AdamW for better generalization)
optimizer: adamw  # Changed from adam
scheduler: steplr
lr: 0.001
lr_decay: 0.95
weight_decay: 0.0001  # Changed from 0 - L2 regularization

## Loss functions - OPTIMIZED MARGINS
margin: 0.3  # Increased from 0.2 for better separation
scale: 32    # Increased from 30 for better training
nPerSpeaker: 2  # Changed from 1 - better representation (note: TEER/TAcc will show 0.00%, ignore it)
nClasses: 140

## Training and test data
train_list: /mnt/ricproject3/2025/data/mini_voxceleb2_train_list.txt
test_list: /mnt/ricproject3/2025/data/mini_test_list.txt
train_path: /mnt/ricproject3/2025/data/mini_voxceleb2
test_path: /mnt/ricproject3/2025/data/mini_voxceleb1

max_test_pairs: 0
eval_batch_size: 1

# Augmentation paths
musan_path: /mnt/ricproject3/2025/data/musan
rir_path: /mnt/ricproject3/2025/data/RIRS_NOISES/simulated_rirs

## Model definition - IMPROVED
n_mels: 80
model: ResNetSE34L  # Keep current model for Phase 1
encoder_type: ASP  # CHANGED from SAP - captures mean + variance (2x better)
nOut: 512
log_input: true  # CHANGED from false - better dynamic range handling

## Load and save paths
save_path: exps/mini_voxceleb1_optimized_phase1
initial_model: ""

## Performance optimization
mixedprec: true
prefetch_factor: 2
persistent_workers: true
gradient_accumulation_steps: 1

## Distributed training
distributed: false
port: "8888"

## Advanced optimization
compile_model: false
enable_profiling: false
